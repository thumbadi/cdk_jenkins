import unittest
import boto3

class TestGlueJob(unittest.TestCase):
    
    def setUp(self):
        self.glue = boto3.client('glue')
        self.job_name = 'my_glue_job'
    
    def test_glue_job_success(self):
        response = self.glue.start_job_run(
            JobName=self.job_name
        )
        job_run_id = response['JobRunId']
        
        status = None
        while status not in ['SUCCEEDED', 'FAILED']:
            response = self.glue.get_job_run(
                JobName=self.job_name,
                RunId=job_run_id
            )
            status = response['JobRun']['JobRunState']
        
        self.assertEqual(status, 'SUCCEEDED')
    
    def test_glue_job_failure(self):
        response = self.glue.start_job_run(
            JobName=self.job_name
        )
        job_run_id = response['JobRunId']
        
        status = None
        while status not in ['SUCCEEDED', 'FAILED']:
            response = self.glue.get_job_run(
                JobName=self.job_name,
                RunId=job_run_id
            )
            status = response['JobRun']['JobRunState']
        
        self.assertEqual(status, 'FAILED')



-------------

# install unittest and boto3 python packages
```
pip install unittest
pip install boto3
```
# configure the aws credentials
```
aws configure
```

# change the name of your aws glue job on the py file 


# run the below command to test that
```
python -m unittest unit_test.py
```

import unittest
from awsglue.utils import getResolvedOptions
from awsglue.context import GlueContext
from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession

class TestGlueJob(unittest.TestCase):
    
    def setUp(self):
        args = getResolvedOptions(sys.argv, ['JOB_NAME'])
        sc = SparkContext()
        self.glueContext = GlueContext(sc)
        self.sparkSession = SparkSession.builder.appName(args['JOB_NAME']).getOrCreate()
        self.job = MyGlueJob(self.glueContext)
        
    def test_glue_job(self):
        input_data = [("foo", 1), ("bar", 2), ("baz", 3)]
        input_df = self.sparkSession.createDataFrame(input_data, ["word", "count"])
        expected_output_data = [("foo", 3), ("bar", 4), ("baz", 5)]
        expected_output_df = self.sparkSession.createDataFrame(expected_output_data, ["word", "count"])
        
        output_df = self.job.run(input_df)
        
        self.assertEqual(output_df.collect(), expected_output_df.collect())

class MyGlueJob:
    
    def __init__(self, glueContext):
        self.glueContext = glueContext
    
    def run(self, input_df):
        return input_df.withColumn("count", input_df["count"] + 2)

