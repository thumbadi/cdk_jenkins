rom pyspark.sql.functions import trim
first_11_columns = temp_df.columns[:11]
condition = reduce(lambda a, b: a & b,[(trim(col(c)).isNull()) | (trim(col(c)) == "") for c in first_11_columns])
filtered_df = temp_df.filter(~condition)
